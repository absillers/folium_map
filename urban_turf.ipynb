{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.3.3-cp310-cp310-win_amd64.whl.metadata (19 kB)\n",
      "Collecting numpy>=1.22.4 (from pandas)\n",
      "  Downloading numpy-2.2.6-cp310-cp310-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\annas\\onedrive\\urban_turf_scrape\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\annas\\onedrive\\urban_turf_scrape\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading pandas-2.3.3-cp310-cp310-win_amd64.whl (11.3 MB)\n",
      "   ---------------------------------------- 0.0/11.3 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 1.3/11.3 MB 7.4 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 3.1/11.3 MB 8.0 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 4.5/11.3 MB 7.4 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 6.0/11.3 MB 7.5 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 7.9/11.3 MB 7.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 10.2/11.3 MB 7.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.3/11.3 MB 7.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.3/11.3 MB 7.0 MB/s  0:00:01\n",
      "Downloading numpy-2.2.6-cp310-cp310-win_amd64.whl (12.9 MB)\n",
      "   ---------------------------------------- 0.0/12.9 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 1.6/12.9 MB 10.5 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 3.4/12.9 MB 8.4 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 5.0/12.9 MB 7.9 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 6.8/12.9 MB 8.2 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 8.4/12.9 MB 8.1 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 10.0/12.9 MB 8.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 11.5/12.9 MB 7.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.8/12.9 MB 8.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.9/12.9 MB 7.3 MB/s  0:00:01\n",
      "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: pytz, tzdata, numpy, pandas\n",
      "\n",
      "   ---------------------------------------- 0/4 [pytz]\n",
      "   ---------------------------------------- 0/4 [pytz]\n",
      "   ---------------------------------------- 0/4 [pytz]\n",
      "   ---------------------------------------- 0/4 [pytz]\n",
      "   ---------------------------------------- 0/4 [pytz]\n",
      "   ---------------------------------------- 0/4 [pytz]\n",
      "   ---------------------------------------- 0/4 [pytz]\n",
      "   ---------------------------------------- 0/4 [pytz]\n",
      "   ---------------------------------------- 0/4 [pytz]\n",
      "   ---------- ----------------------------- 1/4 [tzdata]\n",
      "   ---------- ----------------------------- 1/4 [tzdata]\n",
      "   ---------- ----------------------------- 1/4 [tzdata]\n",
      "   ---------- ----------------------------- 1/4 [tzdata]\n",
      "   ---------- ----------------------------- 1/4 [tzdata]\n",
      "   ---------- ----------------------------- 1/4 [tzdata]\n",
      "   ---------- ----------------------------- 1/4 [tzdata]\n",
      "   ---------- ----------------------------- 1/4 [tzdata]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ---------------------------------------- 4/4 [pandas]\n",
      "\n",
      "Successfully installed numpy-2.2.6 pandas-2.3.3 pytz-2025.2 tzdata-2025.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting requests\n",
      "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests)\n",
      "  Downloading charset_normalizer-3.4.4-cp310-cp310-win_amd64.whl.metadata (38 kB)\n",
      "Collecting idna<4,>=2.5 (from requests)\n",
      "  Downloading idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests)\n",
      "  Downloading urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests)\n",
      "  Downloading certifi-2025.10.5-py3-none-any.whl.metadata (2.5 kB)\n",
      "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Downloading charset_normalizer-3.4.4-cp310-cp310-win_amd64.whl (107 kB)\n",
      "Downloading idna-3.11-py3-none-any.whl (71 kB)\n",
      "Downloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Downloading certifi-2025.10.5-py3-none-any.whl (163 kB)\n",
      "Installing collected packages: urllib3, idna, charset_normalizer, certifi, requests\n",
      "\n",
      "   ---------------------------------------- 0/5 [urllib3]\n",
      "   ---------------------------------------- 0/5 [urllib3]\n",
      "   ---------------------------------------- 0/5 [urllib3]\n",
      "   ---------------------------------------- 0/5 [urllib3]\n",
      "   ---------------------------------------- 0/5 [urllib3]\n",
      "   -------- ------------------------------- 1/5 [idna]\n",
      "   ---------------- ----------------------- 2/5 [charset_normalizer]\n",
      "   ---------------- ----------------------- 2/5 [charset_normalizer]\n",
      "   ---------------- ----------------------- 2/5 [charset_normalizer]\n",
      "   ------------------------ --------------- 3/5 [certifi]\n",
      "   -------------------------------- ------- 4/5 [requests]\n",
      "   -------------------------------- ------- 4/5 [requests]\n",
      "   ---------------------------------------- 5/5 [requests]\n",
      "\n",
      "Successfully installed certifi-2025.10.5 charset_normalizer-3.4.4 idna-3.11 requests-2.32.5 urllib3-2.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting beautifulsoup4\n",
      "  Downloading beautifulsoup4-4.14.2-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4)\n",
      "  Downloading soupsieve-2.8-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\annas\\onedrive\\urban_turf_scrape\\.venv\\lib\\site-packages (from beautifulsoup4) (4.15.0)\n",
      "Downloading beautifulsoup4-4.14.2-py3-none-any.whl (106 kB)\n",
      "Downloading soupsieve-2.8-py3-none-any.whl (36 kB)\n",
      "Installing collected packages: soupsieve, beautifulsoup4\n",
      "\n",
      "   ---------------------------------------- 0/2 [soupsieve]\n",
      "   -------------------- ------------------- 1/2 [beautifulsoup4]\n",
      "   -------------------- ------------------- 1/2 [beautifulsoup4]\n",
      "   ---------------------------------------- 2/2 [beautifulsoup4]\n",
      "\n",
      "Successfully installed beautifulsoup4-4.14.2 soupsieve-2.8\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting geopy\n",
      "  Downloading geopy-2.4.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting geographiclib<3,>=1.52 (from geopy)\n",
      "  Downloading geographiclib-2.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading geopy-2.4.1-py3-none-any.whl (125 kB)\n",
      "Downloading geographiclib-2.1-py3-none-any.whl (40 kB)\n",
      "Installing collected packages: geographiclib, geopy\n",
      "\n",
      "   ---------------------------------------- 0/2 [geographiclib]\n",
      "   -------------------- ------------------- 1/2 [geopy]\n",
      "   -------------------- ------------------- 1/2 [geopy]\n",
      "   -------------------- ------------------- 1/2 [geopy]\n",
      "   -------------------- ------------------- 1/2 [geopy]\n",
      "   -------------------- ------------------- 1/2 [geopy]\n",
      "   -------------------- ------------------- 1/2 [geopy]\n",
      "   ---------------------------------------- 2/2 [geopy]\n",
      "\n",
      "Successfully installed geographiclib-2.1 geopy-2.4.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#scrape urban turf\n",
    "%pip install pandas\n",
    "%pip install requests\n",
    "import requests\n",
    "%pip install beautifulsoup4\n",
    "%pip install geopy\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from geopy.geocoders import Nominatim\n",
    "import time\n",
    "import certifi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor i in range(0, len(urban_turf.Address)):\\n    if type(urban_turf[\"Pipeline Link\"][i]) == str:\\n    \\n        page = requests.get(urban_turf[\"Pipeline Link\"][i])\\n        soup = BeautifulSoup(page.content, \\'html.parser\\')\\n        page_body = soup.body\\n        table = soup.find_all(\\'div\\', class_ = \\'block\\') \\n        txt= str(table)\\n        #every <span class> \\n        #keep everything in between <span class=\"label\">Project type:</span> and </p>\\n\\n        txt = txt.replace(\\'\\r\\', \\'\\').replace(\\'\\n\\', \\'\\')\\n\\n        #remove any instances where there are two spaces +\\n        for k in range(0,100):\\n            txt = txt.replace(\"  \", \"\")\\n        #remove all new lines\\n        txt = txt.split(\"<p>\")  \\n\\n        txt = [x for x in txt if \\'<span class=\"label\">\\' in x] #this is the problem\\n        colnames = []\\n        values = []\\n\\n        for j in range(0, len(txt)):\\n            a = txt[j].split(\"</span>\")\\n\\n            a[0] = re.sub(\\'<span class=\"label\">\\', \"\", a[0])\\n\\n            colnames.append(a[0])\\n\\n            a[1] = re.sub(\"</p>.*\", \"\", a[1])\\n            a[1] = re.sub(\"\\t{4,5}\", \"\", a[1])\\n            a[1] = re.sub(\"<br/>\", \",\", a[1])\\n            a[1] = re.sub(\"\\\\,.*DC\", \", Washington, DC,\", a[1])\\n            a[1] = re.sub(\\'<a href=\"\\', \"\", a[1])\\n            a[1] = re.sub(\\'\" style.*\\', \"\", a[1])\\n            a[1] = re.sub(\\'First\\', \"1st\", a[1])\\n\\n            values.append(a[1])\\n\\n        df_dictionary = pd.DataFrame([ dict(zip(colnames, values))])  #want to add this to urban_turf\\n\\n        #urban_turf = pd.concat([urban_turf, df_dictionary],  ignore_index=True) #this adds it below instead of merging it \\n        \\n        for key, value in df_dictionary.items():\\n            if key in column_names:\\n                urban_turf[key][i] = df_dictionary[key][0]\\n                  \\n\\n\\n\\n\\n\\n#scrape pipeline links\\nfor i in range(0, len(urban_turf.Address)):\\n    if type(urban_turf[\"Pipeline Link\"][i]) == str:\\n    \\n        page = requests.get(urban_turf[\"Pipeline Link\"][i])\\n        soup = BeautifulSoup(page.content, \\'html.parser\\')\\n        page_body = soup.body\\n        table = soup.find_all(\\'div\\', class_ = \\'block\\') \\n        txt= str(table)\\n        #every <span class> \\n        #keep everything in between <span class=\"label\">Project type:</span> and </p>\\n\\n        txt = txt.replace(\\'\\r\\', \\'\\').replace(\\'\\n\\', \\'\\')\\n\\n        #remove any instances where there are two spaces +\\n        for k in range(0,100):\\n            txt = txt.replace(\"  \", \"\")\\n        #remove all new lines\\n        txt = txt.split(\"<p>\")  \\n\\n        txt = [x for x in txt if \\'<span class=\"label\">\\' in x] #this is the problem\\n        colnames = []\\n        values = []\\n\\n        for j in range(0, len(txt)):\\n            a = txt[j].split(\"</span>\")\\n\\n            a[0] = re.sub(\\'<span class=\"label\">\\', \"\", a[0])\\n\\n            colnames.append(a[0])\\n\\n            a[1] = re.sub(\"</p>.*\", \"\", a[1])\\n            a[1] = re.sub(\"\\t{4,5}\", \"\", a[1])\\n            a[1] = re.sub(\"<br/>\", \",\", a[1])\\n            a[1] = re.sub(\"\\\\,.*DC\", \", Washington, DC,\", a[1])\\n            a[1] = re.sub(\\'<a href=\"\\', \"\", a[1])\\n            a[1] = re.sub(\\'\" style.*\\', \"\", a[1])\\n            a[1] = re.sub(\\'First\\', \"1st\", a[1])\\n\\n            values.append(a[1])\\n\\n        df_dictionary = pd.DataFrame([ dict(zip(colnames, values))])  #want to add this to urban_turf\\n\\n        #urban_turf = pd.concat([urban_turf, df_dictionary],  ignore_index=True) #this adds it below instead of merging it \\n        \\n        for key, value in df_dictionary.items():\\n            if key in column_names:\\n                urban_turf[key][i] = df_dictionary[key][0]\\n                  \\n    else:\\n        continue\\n\\ndef get_lat_long(address):\\n    geolocator = Nominatim(user_agent=\"my_geocoder_app\")\\n    time.sleep(1.1)\\n    location = geolocator.geocode(address)\\n\\n    if location:\\n        return location.latitude, location.longitude\\n    else:\\n        return None\\n    \\nurban_turf[\\'Latitude\\'] = \"\"\\nurban_turf[\\'Longitude\\'] = \"\"\\n\\nfor i in range(0, len(urban_turf)):\\n    try:\\n        c = urban_turf[\\'Address:\\'][i]\\n        d = re.sub(\"-[\\\\d]*\", \"\", c)\\n        a = get_lat_long(d)\\n        urban_turf[\\'Latitude\\'][i] =  a[0]\\n        urban_turf[\\'Longitude\\'][i] =  a[1]\\n\\n    except Exception:\\n        pass\\nurban_turf[\\'No. of units:\\'] = pd.to_numeric(urban_turf[\\'No. of units:\\'], errors=\\'coerce\\')\\n'"
      ]
     },
     "execution_count": 786,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "page = requests.get(\n",
    "    \"https://dc.urbanturf.com/pipeline?search_string=&project_type=0&status=0&more_or_less=0&number_of_units=&number_of_units_selector=0&city=0&state=0&zip=0&order_by=last_updated&direction=desc&filtered=Yes&limit=1000\")\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "page_body = soup.body\n",
    "\n",
    "labels = [item for item in page_body.findAll(\"p\")]\n",
    "list_lab = [i.text.strip() for i in labels][1:] \n",
    "list_lab = [word.replace('\\n','') for word in list_lab]\n",
    "\n",
    "torep = {\"Location:            \":\"\", \"Project type:            \":\"\",\"Status:            \":\"\", \"Size:            \":\"\"} #titles of list\n",
    "torep = dict((re.escape(k), v) for k, v in torep.items()) #turn into dictionary using 'torep' value as keys\n",
    "pattern = re.compile(\"|\".join(torep.keys())) #joins with \"|\"\n",
    "\n",
    "desc = []\n",
    "\n",
    "for i in range(0, len(list_lab)):\n",
    "    a = list_lab[i] #first value in list\n",
    "    text = pattern.sub(lambda m:torep[re.escape(m.group(0))], a) #substitute the pattern in each value of the list with \"\"\n",
    "    desc.append(text)\n",
    "\n",
    "seq = range(0, len(desc))\n",
    "\n",
    "urban_turf= pd.DataFrame(\n",
    "    {\"Address\": [desc[i] for i in seq[0::5]],\n",
    "     \"Neighborhood\": [desc[i] for i in seq[1::5]],\n",
    "     \"Project.Type\":[desc[i] for i in seq[2::5]],\n",
    "     \"Status\":[desc[i] for i in seq[3::5]],\n",
    "     \"Size\":[desc[i] for i in seq[4::5]],\n",
    "     \"Pipeline Link\": None,\n",
    "     'Neighborhood:':None,\n",
    "     'Pipeline':None,\n",
    "     'Project type:': None, \n",
    "     'No. of units:': None, \n",
    "     'Types of units:': None, \n",
    "     'Unit sizes:':None, \n",
    "     'Amenities:':None, \n",
    "     'Pricing:':None, \n",
    "     'Website:':None, \n",
    "     'Architect:':None, \n",
    "     'Last updated:':None, \n",
    "     'Address:':None, \n",
    "     'Status:':None, \n",
    "     'First move-ins:':None, \n",
    "     \"Latitude\":None, \n",
    "     \"Longitude\":None})    \n",
    "\n",
    "#can I get the pipeline link from scraping above?\n",
    "\n",
    "def search_pipe_link(row):\n",
    "    ut_address_col = str(row['Address'])\n",
    "    projecttype_col = str(row['Project.Type'])\n",
    "    status_col = str(row['Status'])\n",
    "    searchlink = \"https://dc.urbanturf.com/pipeline?search_string=\" + ut_address_col.replace(\" \", \"_\" ) + \"&project_type=\" + projecttype_col.replace(\" \", \"+\").replace(\"&\", \"%26\") + \"&status=\" + status_col.replace(\",\", \"%2C\").replace(\" \", \"+\") + \"&more_or_less=0&number_of_units=&number_of_units_selector=0&city=0&state=0&zip=0&order_by=last_updated&direction=desc&filtered=Yes\"\n",
    "    time.sleep(1.25)\n",
    "    page = requests.get(searchlink)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    page_body = soup.body\n",
    "    table = page_body.find_all('div', class_ = 'pipeline-item clickable')\n",
    "    if table:\n",
    "        tag = table[0].find('a'py ).get('href')\n",
    "        return tag\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "urban_turf['Pipeline Link'] = urban_turf.apply(search_pipe_link, axis=1)\n",
    "\n",
    "'''\n",
    "#do i still need this?\n",
    "column_names = urban_turf.columns\n",
    "\n",
    "urban_turf.loc[urban_turf['Address'] == \"The MO\", 'Pipeline Link'] = \"https://dc.urbanturf.com/pipeline/715/The_MO\"\n",
    "urban_turf.loc[urban_turf['Address'] == \"Valo\", 'Pipeline Link'] = \"https://dc.urbanturf.com/pipeline/551/Valo\"\n",
    "\n",
    "#if there is a pipeline link\n",
    "\n",
    "def scrape_pipelinelink(row):\n",
    "    page = requests.get(urban_turf[\"Pipeline Link\"][row])\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    table = soup.find_all('div', class_ = 'block') \n",
    "    txt = str(table)\n",
    "    txt = txt.replace('\\r', '').replace('\\n', '')\n",
    "    txt = txt.split(\"<p>\")\n",
    "    txt = [x for x in txt if '<span class=\"label\">' in x]\n",
    "    txt = [txt.split(\"</span>\") for txt in txt]\n",
    "    key = [txt[i][0] for i in list(len(txt))] #need to expand range?\n",
    "    txt = [txt[i][1] for i in list(len(txt))]\n",
    "    key = [x.replace('<span class=\"label\">', \"\") for x in key]\n",
    "    df_dictionary = pd.DataFrame([ dict(zip(key, txt))])\n",
    "    \n",
    "    for key, txt in df_dictionary.items():\n",
    "            if key in column_names:\n",
    "               urban_turf[key][row] = df_dictionary[key][0]\n",
    "\n",
    "urban_turf = urban_turf.apply(scrape_pipelinelink, axis=1)\n",
    "\n",
    "\n",
    "'''\n",
    "'''\n",
    "for i in range(0, len(urban_turf.Address)):\n",
    "    if type(urban_turf[\"Pipeline Link\"][i]) == str:\n",
    "    \n",
    "        page = requests.get(urban_turf[\"Pipeline Link\"][i])\n",
    "        soup = BeautifulSoup(page.content, 'html.parser')\n",
    "        page_body = soup.body\n",
    "        table = soup.find_all('div', class_ = 'block') \n",
    "        txt= str(table)\n",
    "        #every <span class> \n",
    "        #keep everything in between <span class=\"label\">Project type:</span> and </p>\n",
    "\n",
    "        txt = txt.replace('\\r', '').replace('\\n', '')\n",
    "\n",
    "        #remove any instances where there are two spaces +\n",
    "        for k in range(0,100):\n",
    "            txt = txt.replace(\"  \", \"\")\n",
    "        #remove all new lines\n",
    "        txt = txt.split(\"<p>\")  \n",
    "\n",
    "        txt = [x for x in txt if '<span class=\"label\">' in x] #this is the problem\n",
    "        colnames = []\n",
    "        values = []\n",
    "\n",
    "        for j in range(0, len(txt)):\n",
    "            a = txt[j].split(\"</span>\")\n",
    "\n",
    "            a[0] = re.sub('<span class=\"label\">', \"\", a[0])\n",
    "\n",
    "            colnames.append(a[0])\n",
    "\n",
    "            a[1] = re.sub(\"</p>.*\", \"\", a[1])\n",
    "            a[1] = re.sub(\"\\t{4,5}\", \"\", a[1])\n",
    "            a[1] = re.sub(\"<br/>\", \",\", a[1])\n",
    "            a[1] = re.sub(\"\\,.*DC\", \", Washington, DC,\", a[1])\n",
    "            a[1] = re.sub('<a href=\"', \"\", a[1])\n",
    "            a[1] = re.sub('\" style.*', \"\", a[1])\n",
    "            a[1] = re.sub('First', \"1st\", a[1])\n",
    "\n",
    "            values.append(a[1])\n",
    "\n",
    "        df_dictionary = pd.DataFrame([ dict(zip(colnames, values))])  #want to add this to urban_turf\n",
    "\n",
    "        #urban_turf = pd.concat([urban_turf, df_dictionary],  ignore_index=True) #this adds it below instead of merging it \n",
    "        \n",
    "        for key, value in df_dictionary.items():\n",
    "            if key in column_names:\n",
    "                urban_turf[key][i] = df_dictionary[key][0]\n",
    "                  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#scrape pipeline links\n",
    "for i in range(0, len(urban_turf.Address)):\n",
    "    if type(urban_turf[\"Pipeline Link\"][i]) == str:\n",
    "    \n",
    "        page = requests.get(urban_turf[\"Pipeline Link\"][i])\n",
    "        soup = BeautifulSoup(page.content, 'html.parser')\n",
    "        page_body = soup.body\n",
    "        table = soup.find_all('div', class_ = 'block') \n",
    "        txt= str(table)\n",
    "        #every <span class> \n",
    "        #keep everything in between <span class=\"label\">Project type:</span> and </p>\n",
    "\n",
    "        txt = txt.replace('\\r', '').replace('\\n', '')\n",
    "\n",
    "        #remove any instances where there are two spaces +\n",
    "        for k in range(0,100):\n",
    "            txt = txt.replace(\"  \", \"\")\n",
    "        #remove all new lines\n",
    "        txt = txt.split(\"<p>\")  \n",
    "\n",
    "        txt = [x for x in txt if '<span class=\"label\">' in x] #this is the problem\n",
    "        colnames = []\n",
    "        values = []\n",
    "\n",
    "        for j in range(0, len(txt)):\n",
    "            a = txt[j].split(\"</span>\")\n",
    "\n",
    "            a[0] = re.sub('<span class=\"label\">', \"\", a[0])\n",
    "\n",
    "            colnames.append(a[0])\n",
    "\n",
    "            a[1] = re.sub(\"</p>.*\", \"\", a[1])\n",
    "            a[1] = re.sub(\"\\t{4,5}\", \"\", a[1])\n",
    "            a[1] = re.sub(\"<br/>\", \",\", a[1])\n",
    "            a[1] = re.sub(\"\\,.*DC\", \", Washington, DC,\", a[1])\n",
    "            a[1] = re.sub('<a href=\"', \"\", a[1])\n",
    "            a[1] = re.sub('\" style.*', \"\", a[1])\n",
    "            a[1] = re.sub('First', \"1st\", a[1])\n",
    "\n",
    "            values.append(a[1])\n",
    "\n",
    "        df_dictionary = pd.DataFrame([ dict(zip(colnames, values))])  #want to add this to urban_turf\n",
    "\n",
    "        #urban_turf = pd.concat([urban_turf, df_dictionary],  ignore_index=True) #this adds it below instead of merging it \n",
    "        \n",
    "        for key, value in df_dictionary.items():\n",
    "            if key in column_names:\n",
    "                urban_turf[key][i] = df_dictionary[key][0]\n",
    "                  \n",
    "    else:\n",
    "        continue\n",
    "\n",
    "def get_lat_long(address):\n",
    "    geolocator = Nominatim(user_agent=\"my_geocoder_app\")\n",
    "    time.sleep(1.1)\n",
    "    location = geolocator.geocode(address)\n",
    "\n",
    "    if location:\n",
    "        return location.latitude, location.longitude\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "urban_turf['Latitude'] = \"\"\n",
    "urban_turf['Longitude'] = \"\"\n",
    "\n",
    "for i in range(0, len(urban_turf)):\n",
    "    try:\n",
    "        c = urban_turf['Address:'][i]\n",
    "        d = re.sub(\"-[\\d]*\", \"\", c)\n",
    "        a = get_lat_long(d)\n",
    "        urban_turf['Latitude'][i] =  a[0]\n",
    "        urban_turf['Longaitude'][i] =  a[1]\n",
    "\n",
    "    except Exception:\n",
    "        pass\n",
    "urban_turf['No. of units:'] = pd.to_numeric(urban_turf['No. of units:'], errors='coerce')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 781,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_pipelinelink(row):\n",
    "    page = requests.get(urban_turf[\"Pipeline Link\"][row])\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    table = soup.find_all('div', class_ = 'block') \n",
    "    txt = str(table)\n",
    "    txt = txt.replace('\\r', '').replace('\\n', '')\n",
    "    txt = txt.split(\"<p>\")\n",
    "    txt = [x for x in txt if '<span class=\"label\">' in x]\n",
    "    txt = [txt.split(\"</span>\") for txt in txt]\n",
    "\n",
    "    key = [txt[i][0] for i in list(range(0,len(txt)))] #need to expand range?\n",
    "    txt = [txt[i][1] for i in list(range(0,len(txt)))]\n",
    "    #key = [x.replace('<span class=\"label\">', \"\") for x in key]\n",
    "    #df_dictionary = pd.DataFrame([ dict(zip(key, txt))])\n",
    "\n",
    "    \n",
    "    #for key, txt in df_dictionary.items():\n",
    "    #        if key in column_names:\n",
    "    #           urban_turf[key][row] = df_dictionary[key][0]\n",
    "\n",
    "#urban_turf = urban_turf.apply(scrape_pipelinelink, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 788,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index([                                       'Valen',\\n                                   'National Landing',\\n                                             'Rental',\\n                              'Delivered, Leasing Up',\\n                                         '338  units',\\n       'https://dc.urbanturf.com/pipeline/1255/Valen',\\n                                                 None,\\n                                                 None,\\n                                                 None,\\n                                                 None,\\n                                                 None,\\n                                                 None,\\n                                                 None,\\n                                                 None,\\n                                                 None,\\n                                                 None,\\n                                                 None,\\n                                                 None,\\n                                                 None,\\n                                                 None,\\n                                                 None,\\n                                                 None],\\n      dtype='object')] are in the [index]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[788], line 26\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m column_names:\n\u001b[0;32m     24\u001b[0m                urban_turf[key][row] \u001b[38;5;241m=\u001b[39m df_dictionary[key][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m---> 26\u001b[0m urban_turf \u001b[38;5;241m=\u001b[39m \u001b[43murban_turf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscrape_pipelinelink\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\frame.py:9428\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[1;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[0;32m   9417\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[0;32m   9419\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[0;32m   9420\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   9421\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   9426\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m   9427\u001b[0m )\n\u001b[1;32m-> 9428\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\apply.py:678\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw()\n\u001b[1;32m--> 678\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\apply.py:798\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    797\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 798\u001b[0m     results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    800\u001b[0m     \u001b[38;5;66;03m# wrap results\u001b[39;00m\n\u001b[0;32m    801\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\apply.py:814\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    811\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    812\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[0;32m    813\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[1;32m--> 814\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    815\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[0;32m    816\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[0;32m    817\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[0;32m    818\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[788], line 9\u001b[0m, in \u001b[0;36mscrape_pipelinelink\u001b[1;34m(row)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mscrape_pipelinelink\u001b[39m(row):\n\u001b[1;32m----> 9\u001b[0m     page \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(\u001b[43murban_turf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPipeline Link\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[0;32m     10\u001b[0m     soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(page\u001b[38;5;241m.\u001b[39mcontent, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     11\u001b[0m     table \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiv\u001b[39m\u001b[38;5;124m'\u001b[39m, class_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblock\u001b[39m\u001b[38;5;124m'\u001b[39m) \n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\series.py:1038\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1035\u001b[0m     key \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(key, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m)\n\u001b[0;32m   1036\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_values(key)\n\u001b[1;32m-> 1038\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_with\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\series.py:1078\u001b[0m, in \u001b[0;36mSeries._get_with\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1075\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miloc[key]\n\u001b[0;32m   1077\u001b[0m \u001b[38;5;66;03m# handle the dup indexing case GH#4246\u001b[39;00m\n\u001b[1;32m-> 1078\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\indexing.py:1103\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1100\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m   1102\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[1;32m-> 1103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\indexing.py:1332\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1329\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1330\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot index with multidimensional key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1332\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_iterable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1334\u001b[0m \u001b[38;5;66;03m# nested tuple slicing\u001b[39;00m\n\u001b[0;32m   1335\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_nested_tuple(key, labels):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\indexing.py:1272\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_iterable\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1269\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(key, axis)\n\u001b[0;32m   1271\u001b[0m \u001b[38;5;66;03m# A collection of keys\u001b[39;00m\n\u001b[1;32m-> 1272\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_listlike_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1273\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_reindex_with_indexers(\n\u001b[0;32m   1274\u001b[0m     {axis: [keyarr, indexer]}, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_dups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1275\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\indexing.py:1462\u001b[0m, in \u001b[0;36m_LocIndexer._get_listlike_indexer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1459\u001b[0m ax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(axis)\n\u001b[0;32m   1460\u001b[0m axis_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis_name(axis)\n\u001b[1;32m-> 1462\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1464\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m keyarr, indexer\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\indexes\\base.py:5876\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   5873\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   5874\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 5876\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5878\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   5879\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   5880\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\indexes\\base.py:5935\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   5933\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_interval_msg:\n\u001b[0;32m   5934\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 5935\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   5937\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m   5938\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index([                                       'Valen',\\n                                   'National Landing',\\n                                             'Rental',\\n                              'Delivered, Leasing Up',\\n                                         '338  units',\\n       'https://dc.urbanturf.com/pipeline/1255/Valen',\\n                                                 None,\\n                                                 None,\\n                                                 None,\\n                                                 None,\\n                                                 None,\\n                                                 None,\\n                                                 None,\\n                                                 None,\\n                                                 None,\\n                                                 None,\\n                                                 None,\\n                                                 None,\\n                                                 None,\\n                                                 None,\\n                                                 None,\\n                                                 None],\\n      dtype='object')] are in the [index]\""
     ]
    }
   ],
   "source": [
    "column_names = urban_turf.columns\n",
    "\n",
    "urban_turf.loc[urban_turf['Address'] == \"The MO\", 'Pipeline Link'] = \"https://dc.urbanturf.com/pipeline/715/The_MO\"\n",
    "urban_turf.loc[urban_turf['Address'] == \"Valo\", 'Pipeline Link'] = \"https://dc.urbanturf.com/pipeline/551/Valo\"\n",
    "\n",
    "#if there is a pipeline link\n",
    "\n",
    "def scrape_pipelinelink(row):\n",
    "    page = requests.get(urban_turf[\"Pipeline Link\"][row])\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    table = soup.find_all('div', class_ = 'block') \n",
    "    txt = str(table)\n",
    "    txt = txt.replace('\\r', '').replace('\\n', '')\n",
    "    txt = txt.split(\"<p>\")\n",
    "    txt = [x for x in txt if '<span class=\"label\">' in x]\n",
    "    txt = [txt.split(\"</span>\") for txt in txt]\n",
    "    key = [txt[i][0] for i in list(len(txt))] #need to expand range?\n",
    "    txt = [txt[i][1] for i in list(len(txt))]\n",
    "    key = [x.replace('<span class=\"label\">', \"\") for x in key]\n",
    "    df_dictionary = pd.DataFrame([ dict(zip(key, txt))])\n",
    "    \n",
    "    for key, txt in df_dictionary.items():\n",
    "            if key in column_names:\n",
    "               urban_turf[key][row] = df_dictionary[key][0]\n",
    "\n",
    "urban_turf = urban_turf.apply(scrape_pipelinelink, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_pipelinelink(row):\n",
    "    page = requests.get(urban_turf[\"Pipeline Link\"][row])\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    table = soup.find_all('div', class_ = 'block') \n",
    "    txt = str(table)\n",
    "    txt = txt.replace('\\r', '').replace('\\n', '')\n",
    "    txt = txt.split(\"<p>\")\n",
    "    txt = [x for x in txt if '<span class=\"label\">' in x]\n",
    "    txt = [txt.split(\"</span>\") for txt in txt]\n",
    "    key = [txt[i][0] for i in range(0, len(txt))] \n",
    "    txt = [txt[i][1] for i in range(0, len(txt))]\n",
    "    key = [x.replace('<span class=\"label\">', \"\") for x in key]\n",
    "    df_dictionary = pd.DataFrame([ dict(zip(key, txt))])\n",
    "    for key, txt in df_dictionary.items():\n",
    "            if key in column_names:\n",
    "               urban_turf[key][row] = df_dictionary[key][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Project type:'"
      ]
     },
     "execution_count": 708,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {},
   "outputs": [],
   "source": [
    "urban_turf['No. of units:'] = a[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Address</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>Project.Type</th>\n",
       "      <th>Status</th>\n",
       "      <th>Size</th>\n",
       "      <th>Pipeline Link</th>\n",
       "      <th>Neighborhood:</th>\n",
       "      <th>Pipeline</th>\n",
       "      <th>Project type:</th>\n",
       "      <th>No. of units:</th>\n",
       "      <th>...</th>\n",
       "      <th>Amenities:</th>\n",
       "      <th>Pricing:</th>\n",
       "      <th>Website:</th>\n",
       "      <th>Architect:</th>\n",
       "      <th>Last updated:</th>\n",
       "      <th>Address:</th>\n",
       "      <th>Status:</th>\n",
       "      <th>First move-ins:</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Valen</td>\n",
       "      <td>National Landing</td>\n",
       "      <td>Rental</td>\n",
       "      <td>Delivered, Leasing Up</td>\n",
       "      <td>338  units</td>\n",
       "      <td>https://dc.urbanturf.com/pipeline/1255/Valen</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Rental apart...</td>\n",
       "      <td>1650                &lt;/p&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bryant Street Development</td>\n",
       "      <td>Edgewood</td>\n",
       "      <td>Rental</td>\n",
       "      <td>Under Construction, Leasing Up</td>\n",
       "      <td>1650  units</td>\n",
       "      <td>https://dc.urbanturf.com/pipeline/457/Bryant_S...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1650                &lt;/p&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fox 5 Headquarters Redevelopment</td>\n",
       "      <td>Friendship Heights</td>\n",
       "      <td>Rental</td>\n",
       "      <td>Under Construction, Not Yet Leasing</td>\n",
       "      <td>210  units</td>\n",
       "      <td>https://dc.urbanturf.com/pipeline/834/Fox_5_He...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1650                &lt;/p&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Barry Farm Redevelopment</td>\n",
       "      <td>Barry Farm</td>\n",
       "      <td>Condos &amp; Rental apartments</td>\n",
       "      <td>Under Construction, Leasing Up</td>\n",
       "      <td>1,000</td>\n",
       "      <td>https://dc.urbanturf.com/pipeline/579/Barry_Fa...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1650                &lt;/p&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kiley Apartments</td>\n",
       "      <td>Southwest</td>\n",
       "      <td>Rental</td>\n",
       "      <td>Delivered, Leasing Up</td>\n",
       "      <td>330  units</td>\n",
       "      <td>https://dc.urbanturf.com/pipeline/446/Kiley_Ap...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1650                &lt;/p&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>The Hendrix</td>\n",
       "      <td>Trinidad</td>\n",
       "      <td>Rental</td>\n",
       "      <td>Delivered, Leasing Up</td>\n",
       "      <td>45  units</td>\n",
       "      <td>https://dc.urbanturf.com/pipeline/383/The_Hendrix</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1650                &lt;/p&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>Latitude Apartments</td>\n",
       "      <td>Virginia Square</td>\n",
       "      <td>Rental</td>\n",
       "      <td>Delivered, Leasing Up</td>\n",
       "      <td>265  units</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1650                &lt;/p&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>The Pearl</td>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Rental</td>\n",
       "      <td>Delivered, Leasing Up</td>\n",
       "      <td>507  units</td>\n",
       "      <td>https://dc.urbanturf.com/pipeline/468/The_Pearl</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1650                &lt;/p&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>Ten at Clarendon</td>\n",
       "      <td>Clarendon</td>\n",
       "      <td>Rental</td>\n",
       "      <td>Delivered, Leasing Up</td>\n",
       "      <td>144  units</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1650                &lt;/p&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>The Esplanade</td>\n",
       "      <td>National Harbor</td>\n",
       "      <td>Rental</td>\n",
       "      <td>Delivered, Leasing Up</td>\n",
       "      <td>262  units</td>\n",
       "      <td>https://dc.urbanturf.com/pipeline/286/The_Espl...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1650                &lt;/p&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>677 rows  22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Address        Neighborhood   \n",
       "0                               Valen    National Landing  \\\n",
       "1           Bryant Street Development            Edgewood   \n",
       "2    Fox 5 Headquarters Redevelopment  Friendship Heights   \n",
       "3            Barry Farm Redevelopment          Barry Farm   \n",
       "4                    Kiley Apartments           Southwest   \n",
       "..                                ...                 ...   \n",
       "672                       The Hendrix            Trinidad   \n",
       "673               Latitude Apartments     Virginia Square   \n",
       "674                         The Pearl       Silver Spring   \n",
       "675                  Ten at Clarendon           Clarendon   \n",
       "676                     The Esplanade     National Harbor   \n",
       "\n",
       "                   Project.Type                               Status   \n",
       "0                        Rental                Delivered, Leasing Up  \\\n",
       "1                        Rental       Under Construction, Leasing Up   \n",
       "2                        Rental  Under Construction, Not Yet Leasing   \n",
       "3    Condos & Rental apartments       Under Construction, Leasing Up   \n",
       "4                        Rental                Delivered, Leasing Up   \n",
       "..                          ...                                  ...   \n",
       "672                      Rental                Delivered, Leasing Up   \n",
       "673                      Rental                Delivered, Leasing Up   \n",
       "674                      Rental                Delivered, Leasing Up   \n",
       "675                      Rental                Delivered, Leasing Up   \n",
       "676                      Rental                Delivered, Leasing Up   \n",
       "\n",
       "            Size                                      Pipeline Link   \n",
       "0     338  units       https://dc.urbanturf.com/pipeline/1255/Valen  \\\n",
       "1    1650  units  https://dc.urbanturf.com/pipeline/457/Bryant_S...   \n",
       "2     210  units  https://dc.urbanturf.com/pipeline/834/Fox_5_He...   \n",
       "3          1,000  https://dc.urbanturf.com/pipeline/579/Barry_Fa...   \n",
       "4     330  units  https://dc.urbanturf.com/pipeline/446/Kiley_Ap...   \n",
       "..           ...                                                ...   \n",
       "672    45  units  https://dc.urbanturf.com/pipeline/383/The_Hendrix   \n",
       "673   265  units                                               None   \n",
       "674   507  units    https://dc.urbanturf.com/pipeline/468/The_Pearl   \n",
       "675   144  units                                               None   \n",
       "676   262  units  https://dc.urbanturf.com/pipeline/286/The_Espl...   \n",
       "\n",
       "    Neighborhood: Pipeline                                      Project type:   \n",
       "0            None     None                                    Rental apart...  \\\n",
       "1            None     None                                               None   \n",
       "2            None     None                                               None   \n",
       "3            None     None                                               None   \n",
       "4            None     None                                               None   \n",
       "..            ...      ...                                                ...   \n",
       "672          None     None                                               None   \n",
       "673          None     None                                               None   \n",
       "674          None     None                                               None   \n",
       "675          None     None                                               None   \n",
       "676          None     None                                               None   \n",
       "\n",
       "                                  No. of units:  ... Amenities: Pricing:   \n",
       "0                      1650                </p>  ...       None     None  \\\n",
       "1                      1650                </p>  ...       None     None   \n",
       "2                      1650                </p>  ...       None     None   \n",
       "3                      1650                </p>  ...       None     None   \n",
       "4                      1650                </p>  ...       None     None   \n",
       "..                                          ...  ...        ...      ...   \n",
       "672                    1650                </p>  ...       None     None   \n",
       "673                    1650                </p>  ...       None     None   \n",
       "674                    1650                </p>  ...       None     None   \n",
       "675                    1650                </p>  ...       None     None   \n",
       "676                    1650                </p>  ...       None     None   \n",
       "\n",
       "    Website: Architect: Last updated: Address: Status: First move-ins:   \n",
       "0       None       None          None     None    None            None  \\\n",
       "1       None       None          None     None    None            None   \n",
       "2       None       None          None     None    None            None   \n",
       "3       None       None          None     None    None            None   \n",
       "4       None       None          None     None    None            None   \n",
       "..       ...        ...           ...      ...     ...             ...   \n",
       "672     None       None          None     None    None            None   \n",
       "673     None       None          None     None    None            None   \n",
       "674     None       None          None     None    None            None   \n",
       "675     None       None          None     None    None            None   \n",
       "676     None       None          None     None    None            None   \n",
       "\n",
       "    Latitude Longitude  \n",
       "0       None      None  \n",
       "1       None      None  \n",
       "2       None      None  \n",
       "3       None      None  \n",
       "4       None      None  \n",
       "..       ...       ...  \n",
       "672     None      None  \n",
       "673     None      None  \n",
       "674     None      None  \n",
       "675     None      None  \n",
       "676     None      None  \n",
       "\n",
       "[677 rows x 22 columns]"
      ]
     },
     "execution_count": 721,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urban_turf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "urban_turf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_pipe_line(search, projecttype, status):\n",
    "    searchlink = \"https://dc.urbanturf.com/pipeline?search_string=\" + search + \"&project_type=\" + projecttype + \"&status=\" + status + \"&more_or_less=0&number_of_units=&number_of_units_selector=0&city=0&state=0&zip=0&order_by=last_updated&direction=desc&filtered=Yes\"\n",
    "    page = requests.get(searchlink)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    page_body = soup.body\n",
    "    table = page_body.find_all('div', class_ = 'pipeline-item clickable')\n",
    "    if table:\n",
    "        tag = table[0].find('a').get('href')\n",
    "        return tag\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torep = {\"Location:            \":\"\", \"Project type:            \":\"\",\"Status:            \":\"\", \"Size:            \":\"\"} #titles of list\n",
    "torep = dict((re.escape(k), v) for k, v in torep.items()) #turn into dictionary using value as keys\n",
    "pattern = re.compile(\"|\".join(torep.keys())) #joins\n",
    "\n",
    "for i in range(0, len(list)):\n",
    "    a = list[i] #first value in list\n",
    "    text = pattern.sub(lambda m:torep[re.escape(m.group(0))], a) #re.escape - remove extra values, #substitute the pattern in each value of the list (a)\n",
    "    desc.append(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
